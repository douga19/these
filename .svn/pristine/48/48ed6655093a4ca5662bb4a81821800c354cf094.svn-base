\documentclass[11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{enumerate}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}

% New commands
\newcommand{\xt}{$(X_t)$ }
\newcommand{\om}{$\Omega$ }


\begin{document}

\title{Lecture sur les chaînes de Markov, pistes pour la génération aléatoire de polytopes entiers en utilisant les chaînes de Markov}
\author{Julien David, Rakotonarivo Rado}
\maketitle



Ce document va décrire une nouvelle approche pour faire de la génération aléatoire en utilisant les chaînes de Markov. Les objets à engendrer sont
toujours les mêmes: les polytopes entiers contenus dans l'hypercube ${[0,k]}^d$. L'idée principale de la génération aléatoire en utilisant les chaînes de Markov est la suivante: modéliser une chaîne de Markov dont les états seront nos $(d,k)$-polytopes, lancer des marches sur notre chaîne jusqu'à ce qu'on atteigne une distribution stationnaire, et enfin prouver que cette distribution stationnaire est unique et uniforme. De ce fait, on aura construit un générateur aléatoire uniforme de $(d,k)$-polytopes.

Bien que l'idée de laquelle on part soit simple, il réside cependant plusieurs difficultés. Premièrement, notre espace des états est inconnu - où plutôt, pas entièrement définie, la matrice de transition est également inconnue. De plus, notre espace des états sera relativement grand, impliquant de premier abord un temps de mélange assez désastreux. Et enfin, assurer une distribution uniforme nécessite que certaines conditions sur notre matrice de transition soient vérifiées.

Toutefois, partir sur une chaîne de Markov semble être une piste sérieuse vu les nombreux résultats et différentes techniques qui sont déjà à notre disposition \cite{levin2009markov}. Il y a également le fait qu'on peut faire une expérimentation: modéliser notre chaîne et lancer une battérie de tests dessus.

Le travail sur cette nouvelle approche sera principalement de:
\begin{itemize}
  \item Trouver des opérations locales sur nos $(d,k)$-polytopes pour pouvoir passer d'un état à un autre.
  \item Utiliser les techniques et les résultats connus sur les chaînes de Markov pour optimiser le temps de mélange.
  \item Réfléchir sur des idées de preuves pour l'uniformité du générateur.
\end{itemize}

Ceci étant, ce document sera structuré de la manière suivante. Dans un premier temps, un bref rappels des principaux résultats sur les chaînes de Markov - tous essentiellement proviennent de notre lecture sur \cite{levin2009markov}. Et dans un deuxième temps notre modèle concret de générateur en utilisant les chaînes de Markov.

\section{Chaînes de Markov}

Comme les polytopes entiers dans ${[0,k]}^d$ sont finis, on va s'interesser aux chaînes de Markov à espace d'états fini. Dans toute la suite du document, on assumera que la chaîne de Markov étudiée est une chaîne à espace d'états fini.

\subsection{Définitions}

Une chaîne de Markov finie $(X_t)_{t\geq{0}}$ est un processus qui évolue en temps sur les éléments d'un espace $\Omega$ fini. Se déplacer d'un état $x \in \Omega$ à un autre état de $\Omega$ suit une distribution fixe $P(x,\cdot)$. C'est une séquence de variables aléatoires $(X_0, X_1, \cdots)$ à valeur dans $\Omega$.

La valeur de \xt étant l'état de la chaîne à l'instant $t$, la \textbf{propriété de Markov} sur \xt assure que l'état à l'instant $t+1$ ne dépend que de l'état à l'instant $t$.

La matrice de transition $P$ de \xt qui décrit les transitions entre les états de \om, est une matrice stochastique dont la $x-$ème ligne désigne la distribution $P(x,\cdot)$. On a:

\begin{equation}
  \sum_{y \in \Omega} P(x,y) = 1 \quad \forall{x \in \Omega}
\end{equation}

\begin{figure}
  \begin{center}
    \includegraphics[width=5cm]{assets/frog}
    \caption{Une chaîne de Markov tel que: $\Omega = \{x,y\}$, $P(x,x) = 1-p$, $P(x,y) = p$,  $P(y,x) = q$ et $P(y,y) = 1-q$}
    \label{fig:fig1}
  \end{center}
\end{figure}

\subsection{Propriétés}

Soient $X_t$ une chaîne de Markov, \om son espace des états et $P$ sa matrice de transition.

\subsubsection{Irréductibilité}

La matrice P de $X_t$ est \textbf{irréductible} si tout état $x$ de \om est accessible depuis n'importe quel état de \om. En d'autres mots, cela signifie que le graphe de $X_t$ est fortement connexe. Formellement, on a:

\begin{equation}
  \exists r_0 \quad \ : \quad \forall r > r_0 \quad P^r(x,y) > 0 \quad \forall x,y \in \Omega
\end{equation}

\subsubsection{Périodicité}

On définit par $\mathcal{T}(x):=\{t\geq{1} \ : P^t(x,x)>0\}$, l'ensemble des temps où la chaîne retourne en x. La \textbf{période} de $x$ est définit par $\mathrm{pgcd}(\mathcal{T}(x))$.

\newtheorem{propriete}{Propriété}
\begin{propriete}
  Si $P$ est irreductible alors tous les états de \om ont la même période.
\end{propriete}

$X_t$ est dite \textbf{apériodique} si tous les états de \om ont pour période 1, sinon elle est dite \textbf{périodique}.

\subsubsection{Hitting time et premier temps de retour}

Pour tout état $x \in \Omega$ on défini le \textbf{hitting time} par:

\begin{equation}
  \tau_x:=\min \{t\geq{0} \ : X_t = x\},
\end{equation}

le premier moment où la chaîne visite $x$. 







\subsection{Distribution stationnaire}

On note par $\mu_t$ le vecteur ligne qui donne la distribution de probabilité sur \om à l'instant $t$ et par $\mu_t(x)$ la probabilité d'être en $x$ l'instant $t$, i.e. $\mu_t(x) = \mathbf{P}\{X_t = x \} \quad \forall x \in \Omega$. Obtenir la distribution à l'instant $t+1$ revient à appliquer une fois à $\mu_t$ la matrice de transition $P$. On a:

\begin{equation}
  \mu_t = \mu_{t-1}P \quad \forall t\geq{1}
\end{equation}

En partant d'une distribution initiale $\mu_0$, on a:

\begin{equation}
  \mu_t = \mu_0P^t \quad \forall t\geq{0}
\end{equation}

Une distribution $\pi$ est dite stationnaire pour \xt si elle satisfait

\begin{equation}
  \pi = \pi P
\end{equation}

De manière équivalente:

\begin{equation}
  \pi(y) = \sum_{x \in \Omega} \pi(x)P(x,y) \quad \forall y \in \Omega
\end{equation}

Le \textbf{temps de mélange} est le temps minimum pour atteindre la distribution stationnaire si elle existe.

\clearpage
\bibliographystyle{plain}
\bibliography{biblio.bib}

\end{document}
